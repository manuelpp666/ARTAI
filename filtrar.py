# ================================================================
# limpiar_wiki.py ‚Äî Limpieza y preparaci√≥n de dataset Wikipedia
# ================================================================
import os
import re

input_folder = "datasets/espa√±ol/arte_traducido"
output_file = "dataset_wikipedia.txt"

# ---------------------------------------------------------------
# üîπ Lista de abreviaturas que NO deben separar frases
# ---------------------------------------------------------------
abrevs = [
    "Sr", "Sra", "Dr", "Dra", "Lic", "Ing", "Prof",
    "a.C", "d.C",
    "etc", "p√°g", "Cap", "Ej", "No", "vs",
    "EE.UU", "U.S.A"
]

# ---------------------------------------------------------------
# üîπ Funci√≥n mejorada para separar frases
# ---------------------------------------------------------------
def separar_frases(text):
    # Patr√≥n general: busca . ! ? seguido de espacio y may√∫scula
    pattern = re.compile(r'([.!?])(\s+)(?=[A-Z√Å√â√ç√ì√ö√ë√ú])')

    def reemplazo(match):
        start = match.start()
        # Tomamos hasta 10 chars antes del signo
        antes = text[max(0, start-10):start]

        # Revisar si termina con alguna abreviatura
        if any(antes.endswith(abrev) for abrev in abrevs):
            return match.group(1) + match.group(2)  # No cortar
        # Revisar si es n√∫mero decimal
        if re.search(r'\d\.$', antes):
            return match.group(1) + match.group(2)
        # En otros casos, cortar l√≠nea
        return match.group(1) + '\n'

    return pattern.sub(reemplazo, text)


# ---------------------------------------------------------------
# üîπ Funci√≥n principal de limpieza
# ---------------------------------------------------------------
def clean_wiki_text(text):
    # --- 1. Quitar referencias y notas ---
    text = re.sub(r'<ref.*?>.*?</ref>', ' ', text, flags=re.DOTALL)
    text = re.sub(r'\[\d+\]', ' ', text)  # [1], [2]...
    text = re.sub(r'\[\[.*?\|.*?\]\]', lambda m: m.group(0).split('|')[1][:-2] if '|' in m.group(0) else '', text)
    text = re.sub(r'\[\[|\]\]', '', text)

    # --- 2. Convertir t√≠tulos de secciones en tokens especiales ---
    text = re.sub(r'={2,}\s*(.*?)\s*={2,}', r' [SECCION] \1 [SECCION] ', text)

    # --- 3. Conservar letras, n√∫meros y signos b√°sicos ---
    text = re.sub(r'[^A-Za-z√Å√â√ç√ì√ö√°√©√≠√≥√∫√ë√±√ú√º0-9.,;:!?()\'"¬ø¬°\-\s‚Äî]', ' ', text)

    # --- 4. Eliminar repeticiones de signos ---
    text = re.sub(r'([.,;:!?()\'"¬ø¬°\-‚Äî])\1+', r'\1', text)

    # --- 5. Reemplazar m√∫ltiples espacios por uno ---
    text = re.sub(r'\s+', ' ', text)

    # --- 6. Quitar espacios antes de puntuaci√≥n ---
    text = re.sub(r'\s+([.,;:!?])', r'\1', text)

    # --- 7. Insertar saltos de l√≠nea √∫tiles ---
    text = re.sub(r'\[SECCION\]', r'\n[SECCION]\n', text)
    text = separar_frases(text)

    # --- 8. Normalizar saltos de l√≠nea ---
    text = re.sub(r'\n+', '\n', text)

    return text.strip()

# ---------------------------------------------------------------
# üîπ Procesar todos los archivos .txt
# ---------------------------------------------------------------
all_texts = []

for filename in sorted(os.listdir(input_folder)):
    if filename.endswith(".txt"):
        path = os.path.join(input_folder, filename)
        with open(path, "r", encoding="utf-8", errors="ignore") as f:
            text = f.read()
            cleaned = clean_wiki_text(text)
            all_texts.append(cleaned)
            print(f"Procesado: {filename} ({len(cleaned)} caracteres limpios)")

# ---------------------------------------------------------------
# üîπ Guardar resultado final
# ---------------------------------------------------------------
final_text = "\n".join(all_texts)

with open(output_file, "w", encoding="utf-8") as f:
    f.write(final_text)

print(f"\n‚úÖ Archivo final creado: {output_file}")
print(f"Total caracteres: {len(final_text):,}")
